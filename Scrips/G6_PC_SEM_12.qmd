---
title: "G6_PRACTICA_S12"
format: html
editor: visual
---

## GRUPO 06

Choquecahua Bendezú Carol Neyduth\
Clemente Valenzuela Brithney Coraima\
Cortez Carbonell Dariana Ysabel\
Felix Yataco Maria Fernanda\
Huaripuma Lozano Anyelina Yuli\
Larico Mamani Liz Heydi Patricia

## instalar los paquetes

```{r}
install.packages("performance")
install.packages("cardx")
install.packages("broom.helpers")
```

## Cargar los paquetes

```{r}
library(tidyverse) 
library(here) 
library(rio) 
library(gtsummary) 
library(car) 
library(survival) 
library(performance)
library(cardx)
library(broom.helpers)
```

## 1 Modelos univariados (no ajustados) vs. multivariados (ajustados)

Hasta ahora, hemos explorado modelos de regresión que evalúan un predictor a la vez. A estos se les denomina modelos univariados o no ajustados, ya que solo consideran una variable predictora. Sin embargo, datasets utilizados en estas sesiones, al igual que muchos datos que probablemente recolectes, provienen de estudios observacionales. Es decir, no existe un control estricto sobre qué individuos se incluyen en el análisis y cuáles no. Esto implica que múltiples factores pueden influir en el desenlace de interés de manera simultánea.

Por esta razón, no es adecuado extraer conclusiones definitivas a partir de modelos no ajustados, ya que estos ignoran el efecto de posibles variables de confusión. En su lugar, es necesario realizar un análisis multivariado o ajustado, que permita considerar de manera simultánea varios predictores potenciales.

Por ejemplo, es poco probable que solo el tipo de accidente cerebrovascular (ACV) —isquémico o hemorrágico— determine la probabilidad de fallecer tras un evento de este tipo. Factores como la edad, el sexo, las comorbilidades preexistentes y los hábitos de vida también pueden afectar de manera importante este riesgo. Ignorar estas variables podría conducir a estimaciones sesgadas o erróneas.

## 1.1 Interpretación general del modelo ajustado

Cuando se incluyen varias covariables en un modelo de regresión, se obtienen medidas de efecto ajustadas, como el Odds Ratio ajustado (OR ajustado) en la regresión logística, o el riesgo relativo ajustado (RR ajustado) en la regresión de Cox. Estas medidas estiman la asociación entre una variable específica y el desenlace de interés, mientras se controla el efecto de las demás covariables incluidas en el modelo.

Por ejemplo, el OR ajustado para fallecer tras un ACV isquémico indica la fuerza de esta asociación independientemente de otros factores como la edad, el sexo o las comorbilidades del paciente.

En esta sesión aplicaremos tanto modelos univariados (no ajustados) como multivariados (ajustados), utilizando el dataset previamente analizados en sesión de regresión logística.

## 1.2 Selección de variables para el modelo multivariado (ajustado)

La selección de variables consiste en decidir cuáles variables incluir en un modelo a partir de una lista completa de predictores disponibles, eliminando aquellas que son irrelevantes o redundantes. El objetivo es construir un modelo que explique adecuadamente el desenlace y permita realizar predicciones precisas sin sobreajustar los datos.

Existen al menos dos enfoques principales para la selección de variables:

### **1.2.1 Selección automática**

Este método emplea algoritmos automáticos —disponibles en R— para determinar qué variables incluir en el modelo. Las técnicas automáticas de selección se basan en criterios estadísticos como los valores p o los coeficientes de regresión. Los algoritmos difieren principalmente en la estrategia que utilizan para evaluar la inclusión o exclusión de variables en el modelo final.

Dependiendo de la dirección del algoritmo (forward, backward o stepwise), el resultado será un subconjunto seleccionado de variables. Para comparar entre distintos modelos generados por estos algoritmos, puede utilizarse el Criterio de Información de Akaike (Akaike Information Criterion, AIC), que estima el error de predicción y, por tanto, la calidad relativa de los modelos estadísticos para un conjunto de datos dado. En términos simples, cuanto menor sea el valor del AIC, mejor es el modelo en términos de equilibrio entre ajuste y complejidad.

Hay al menos tres algoritmos de selección automática de variables:

1.  Eliminación hacia atrás (*Backward elimination*),

2.  Selección hacia adelante (*Forward selection*) y

3.  Selección paso a paso (*Stepwise selection*).

Cada uno de estos métodos tiene ventajas y limitaciones. Entre ellos, la selección paso a paso es una técnica ampliamente utilizada en investigaciones en ciencias de la salud, ya que combina procedimientos de selección hacia adelante y hacia atrás. Esto permite añadir o eliminar variables de manera iterativa en función de criterios estadísticos, optimizando el modelo en ambos sentidos.

Sin embargo, la selección automática de variables no debería realizarse de manera aislada; es recomendable complementarla con una evaluación de la multicolinealidad. La multicolinealidad ocurre cuando dos o más variables independientes están altamente correlacionadas, lo que puede distorsionar las estimaciones del modelo. Por ejemplo, no es apropiado incluir simultáneamente el recuento total de leucocitos y el recuento de neutrófilos, dado que ambas variables están estrechamente relacionadas; en estos casos, es preferible seleccionar solo una de ellas.

En regresión, una herramienta común para detectar multicolinealidad es el Factor de Inflación de la Varianza (VIF, por sus siglas en inglés). De manera general, se interpreta así:

-   VIF de 1 indica que no hay multicolinealidad.
-   VIF entre 1 y 5 sugiere una multicolinealidad moderada.
-   VIF superior a 5 o 10 indica una multicolinealidad alta que puede requerir atención.

### **1.2.2 Selección intencionada de variables**

La selección intencionada de variables sigue una serie de pasos que combinan criterios estadísticos y consideraciones clínicas. Estos pasos incluyen:

-   Evaluación univariada de variables: Se realiza un análisis univariado para cada variable independiente con respecto a la variable de desenlace. Las variables que presentan una asociación estadísticamente significativa (habitualmente con un valor de p menor a 0.20) o que son consideradas clínicamente relevantes se seleccionan para su inclusión inicial en el modelo multivariado, independientemente de su significancia estadística.

-   Comparación de modelos multivariados: Las variables seleccionadas se incluyen en un modelo multivariado preliminar. A partir de este modelo, las variables que no alcanzan un nivel de significancia estadística estricto (por ejemplo, p \> 0.05) pueden ser consideradas para eliminación. Posteriormente, se comparan el modelo original (con todas las variables) y el modelo reducido (con las variables eliminadas) para evaluar si la simplificación del modelo afecta negativamente su capacidad explicativa o predictiva. Esta comparación puede realizarse mediante pruebas como la de razón de verosimilitud (Likelihood Ratio Test) o criterios de información (AIC/BIC).

-   Evaluación de interacciones: Es importante explorar posibles términos de interacción entre variables que, en combinación, podrían modificar el efecto sobre el desenlace.

## 2. Ejemplos de análisis univariado y multivariado en una regresión logística

### 2.1 El dataset para este ejercicio

Para ilustrar el proceso de análisis multivariado en un modelo de regresión logística, se empleará el dataset `cancer_cervical`. Este conjunto de datos incluye información de 218 pacientes siendo evaluadas en cuanto al conocimiento actitudinal sobre cancer cervical. Las variables registradas comprenden el desenlace de conocimiento actitudinal como practica (correcta o incorrecta), actitud (positiva o negativa), conocimiento (si tiene o no tiene), antecedentes, estado marital, uso de anticonceptivos, entre otras variables.

Cargando los datos

```{r}
cancer_cervical_0 <- import(here("data", "cancer_cervical.csv"))
```

Un vistazo a los datos

```{r}
head(cancer_cervical_0)
```

### 2.2 El análisis univariado

En esta sección se estimarán los Odds Ratios (OR) de cada variable de manera independiente, es decir, sin ajuste por otras covariables.

Antes de realizar este análisis, es necesario definir las categorías de referencia para las variables categóricas mediante la función `mutate()` en combinación con `relevel()`. Este paso asegura que la interpretación de los OR se haga en relación con la categoría de referencia seleccionada. El resultado se guarda en un nuevo objeto llamado `cancer_cervical_1`.

```{r}
cancer_cervical_1 <- cancer_cervical_0 |> 
  mutate(Actitud = relevel(as.factor(Actitud), ref = "Positiva"),
         Conocimiento = relevel(as.factor(Conocimiento), ref = "Si tiene"),
         Practica = relevel(as.factor(Practica), ref = "Correcta")) |> 
  na.omit()
```

Para obtener la tabla con los resultados del análisis univariado, se utiliza la función `tbl_uvregression()`, que permite generar tablas con las estimaciones de regresión logística para cada variable incluida. Entre sus argumentos se especifican el método de regresión, las variables a analizar, la familia de distribución (binomial para modelos logísticos), y opciones de presentación de los resultados como los intervalos de confianza, valores p y formato de los estimadores.

```{r}
tabla_reg_log_univ <- cancer_cervical_1 |>
  tbl_uvregression(
    include = c(Edad, Estado_marital, Nivel_de_educación, Religión, Etnia,
                Procedencia, Ocupación, Ocupación_convi, Antecedentes_fam, Antecedentes_ets, Edad_relacion_sexual, Parejas_sex, num_hijos, Usa_anticoceptivo, tipo_de_anticoceptivo, Conocimiento, Grado_de_conocimiento, Actitud),
    y = Practica,
    method = glm,
    method.args = list(family = binomial),
    exponentiate = TRUE,
    conf.int = TRUE,
    hide_n = TRUE,
    add_estimate_to_reference_rows = FALSE,
    pvalue_fun = ~ style_pvalue(.x, digits = 3),
    estimate_fun = ~ style_number(.x, digits = 2),
    label = list(
      Edad ~ "Edad (años)",
      Estado_marital ~ "Estado marital",
      Nivel_de_educación ~ "Nivel de educación",
      Religión ~ "Religión",
      Etnia ~ "Etnia",
      Procedencia ~ "Procedencia",
      Ocupación ~ "Ocupación",
      Ocupación_convi ~ "Ocupación de conviviente",
      Antecedentes_fam ~ "Antecedentes familiares",
      Antecedentes_ets ~ "Antecedentes de ETS",
      Edad_relacion_sexual ~ "Edad de relación sexual",
      Parejas_sex ~ "Número de parejas sexuales",
      num_hijos ~ "Número de hijos",
      Usa_anticoceptivo ~ "Usa anticoncetivos",
      tipo_de_anticoceptivo ~ "Tipo de anticonceptivo",
      Conocimiento ~ "Conocimiento",
      Grado_de_conocimiento ~ "Grado de conocimiento",
      Actitud ~ "Actitud"
    )
  ) |>
  bold_labels() |>
  bold_p(t = 0.05) |>
  modify_header(estimate = "**OR no ajustado**", p.value = "**Valor P**")
```

En esta tabla, los resultados se expresan como odds ratios no ajustados (OR) con sus respectivos intervalos de confianza al 95% y valores p.

```{r}
tabla_reg_log_univ
```

**¿Cómo interpretar?**

En cuanto a las variables numéricas, se observa que la mayoria presentan un **OR mayor a 1**, lo que sugiere una posible asociación positiva con el desenlace (incorrecto) en cuanto a conocimiento actitudinal sobre cancer cervical, excluyendo a las variables edad (0.98), religión-ninguna (0.27), etnia-mestizo (0.65), etnia-otro (0.57), procedencia-urbano (0.94), numero de hijos(0.87) y tipo de anticonceptivo-DIU (0.79) los cuales tienen un **OR menor a 1**, lo cual quiere decir una disminución en el porcentaje de presentar el desenlace.

Por otra parte, únicamente las variables `ocupación de conviviente`, `estado marital-soltera` y `grado de conocimiento bajo` mostraron una asociación estadísticamente significativa (**valor p \< 0.05**).

Específicamente, si la ocupacion del conviviente es otra de las que se menciona, las probabilidades (odds) de tener una practica incorrecta se incrementan en un 110% (OR = 2.10).

Tambien, si la paciente tiene el estado marital de soltera, las probabilidades (odds) de tener una practica incorrecta se incrementan en un 134% (OR = 2.34).

De manera similar, si la,paciente cuenta con un grado de conocimiento bajo, las odds de fallecer aumentan en un 239% (OR = 3.39).

### 2.3 El análisis multivariado

Para el análisis de regresión logística multivariada, se aplicó una estrategia de selección automática de variables utilizando tres enfoques: eliminación hacia atrás (*backward elimination*), selección hacia adelante (*forward selection*) y selección paso a paso (*stepwise selection)*.

**Paso 1. Ajuste del modelo inicial**

Ajustamos un modelo de regresión logística binaria que incluya todas las variables candidatas

```{r}
var_modelo <- glm(
  Practica ~ Edad + Estado_marital + Nivel_de_educación + Religión + 
    Etnia + Procedencia + Ocupación + Ocupación_convi + 
    Antecedentes_fam + Edad_relacion_sexual + Parejas_sex + num_hijos +
    tipo_de_anticoceptivo + Conocimiento + Actitud + Antecedentes_ets +
    Grado_de_conocimiento + Usa_anticoceptivo,
  data = cancer_cervical_1,
  family = binomial(link = "logit")
)
```

**Paso 2a. Realizamos la selección de variables** usando la técnica Eliminación hacia atrás (Backward elimination).

```{r}
multi_backward <- var_modelo |>
  step(direction = "backward", trace = FALSE)
```

**Paso 2b. Realizamos la selección de variables** usando la técnica Selección hacia adelante (Forward selection).

```{r}
multi_forward <- var_modelo |>
  step(direction = "forward", trace = FALSE)
```

**Paso 2c. Realizamos la selección de variables** usando la técnica Selección paso a paso (Stepwise selection).

```{r}
multi_stepwise <- var_modelo |>
  step(direction = "both", trace = FALSE)
```

Los resultados de la selección de las variables para el modelo se han guardado en los objetos: multi_backward, multi_forward, y multi_stepwise. El siguiente paso es comparar los valores de AIC y la multicolinealidad entre las variables seleccionadas por cada uno de los modelos.

**Paso 3. Estimados el AIC para los modelos.**

Podemos visualizar el AIC y cuáles variables han sido seleccionadas en cada modelo, usando la función summary.

```{r}
summary(multi_backward)
```

```{r}
summary(multi_forward)
```

```{r}
summary(multi_stepwise)
```

### **2.4 Conclusión**

Los modelos obtenidos mediante eliminación hacia atrás (backward elimination) y selección paso a paso (stepwise selection) presentaron el menor valor de AIC (273.76), indicando un mejor ajuste en comparación con el modelo generado mediante selección hacia adelante (forward selection). Además, ambos modelos seleccionaron el mismo conjunto de variables. Por el contrario, la técnica de selección hacia adelante mantuvo todas las variables originales, lo que resultó en un modelo más complejo sin mejorar el AIC.

### 2.5 Evaluación de colinealidad

Finalmente, evaluamos la colinealidad usando la función check_collinearity() del paquete performance.

```{r}
performance::check_collinearity(multi_backward, ci = NULL)
```

No se pudo evaluar la colinealidad en el modelo generado por selección hacia atrás (multi_backward) debido a que solo contiene una variable predictora, lo cual imposibilita el cálculo de colinealidad entre múltiples variables.

```{r}
performance::check_collinearity(multi_forward, ci = NULL)
```

El análisis mostró que la mayoría de los predictores presentaron valores de VIF por debajo de 5, indicando una colinealidad baja o aceptable. Por ejemplo, variables como Edad (VIF = 2.96), Nivel_de_educación (VIF = 2.07), y Grado_de_conocimiento (VIF = 2.52) no presentan problemas importantes de colinealidad.

Sin embargo, se identificaron dos variables con colinealidad elevada:

La variable ocupación_convi presentó un VIF de 5.83, lo cual indica colinealidad moderada.

La variable ocupación presentó un VIF de 15.18

```{r}
performance::check_collinearity(multi_stepwise, ci = NULL)
```

No se identificaron problemas de colinealidad entre las variables del modelo final los valores de VIF se encontraron en rangos muy bajos, lo que indica que los coeficientes estimados del modelo no están inflados por redundancia entre las variables predictoras

### **2.6 Conclusión**

Los modelos generados mediante eliminación hacia atrás (backward elimination) y selección paso a paso (stepwise selection) mostraron valores de VIF bajos y cercanos a 1 para las variables seleccionadas, lo cual indica una baja colinealidad entre las variables incluidas en dichos modelos. Esto sugiere que las estimaciones obtenidas de los coeficientes no se ven afectadas por redundancia entre predictores, lo que mejora la estabilidad del modelo.

Por otro lado, el modelo generado mediante la técnica de selección hacia adelante (forward selection) presentó problemas de colinealidad más evidentes. En particular, las variables ocupación (VIF = 15.18) y ocupación_convi (VIF = 5.83) mostraron niveles de colinealidad moderada a severa, con tolerancias muy bajas. Este hallazgo sugiere que estas variables comparten gran parte de su varianza explicativa con otras variables del modelo, lo cual puede afectar la precisión de sus coeficientes. Este patrón de colinealidad puede explicar por qué dichas variables no fueron retenidas en los modelos seleccionados mediante backward ni stepwise, dado que los algoritmos de selección buscan minimizar la redundancia entre predictores.

### 2.7 Modelo final

El modelo final fue seleccionado mediante la técnica stepwise, al presentar el menor AIC (273.36) y ausencia de colinealidad. Este incluye tres variables independientes: Grado_de_conocimiento, num_hijos y Usa_anticonceptivo, que serán reportadas en el análisis multivariado final.

## 3 Reporte del análisis univariado y multivariado

Como en las sesiones anteriores, reportaremos los resultados del modelo final de regresión logística.

Tabla para los resultados de la regresión univariado (no ajustado)

```{r}
tabla_univ <- cancer_cervical_1 |>
  tbl_uvregression(
    include = c(Edad, Estado_marital, Nivel_de_educación,
                Usa_anticoceptivo, num_hijos, Grado_de_conocimiento),
    y = Practica,
    method = glm,
    method.args = list(family = binomial),
    exponentiate = TRUE,
    conf.int = TRUE,
    hide_n = TRUE,
    add_estimate_to_reference_rows = FALSE,
    pvalue_fun = ~ style_pvalue(.x, digits = 3),
    estimate_fun = ~ style_number(.x, digits = 2),
    label = list(
      Edad ~ "Edad (años)",
      Estado_marital ~ "Estado civil",
      Nivel_de_educación ~ "Nivel educativo",
      Usa_anticoceptivo ~ "Uso de anticonceptivos",
      num_hijos ~ "Número de hijos",
      Grado_de_conocimiento ~ "Grado de conocimiento"
    )
  ) |>
  bold_labels() |>
  bold_p(t = 0.05) |>
  modify_header(
    estimate = "**OR no ajustado**",
    p.value = "**valor p**"
  )
```

Tabla para los resultados de la regresión multivariable (ajustado)

```{r}
tabla_multi <- glm(
  Practica ~ Grado_de_conocimiento + num_hijos + Usa_anticoceptivo,
  family = binomial(link = "logit"),
  data = cancer_cervical_1
) |>
  tbl_regression(
    exponentiate = TRUE,
    conf.int = TRUE,
    pvalue_fun = ~ style_pvalue(.x, digits = 3),
    estimate_fun = ~ style_number(.x, digits = 2),
    label = list(
      Grado_de_conocimiento ~ "Grado de conocimiento",
      num_hijos ~ "Número de hijos",
      Usa_anticoceptivo ~ "Uso de anticonceptivos"
    )
  ) |>
  bold_labels() |>
  bold_p(t = 0.05) |>
  modify_header(
    estimate = "**OR ajustado**",
    p.value = "**Valor p**"
  )

```

La tabla final la construimos usando la función `tbl_merge()`. De modo que la tabla del análisis univariado o no ajustado y multivariado o ajustado, se muestren lado a lado.

```{r}
tabla_final2 <- 
  tbl_merge(
    list(tabla_univ, tabla_multi),
    tab_spanner = c("**Univariado**", "**Multivariado**")
)
```

```{r}
tabla_final2
```

## 3.1 ¿Cómo interpretar?

En el modelo de regresión logística ajustado, las variables Grado de conocimiento y Número de hijos mostraron asociaciones estadísticamente significativas con la práctica incorrecta sobre el conocimiento actitudinal del cáncer cervical, mientras que Edad, Estado civil, Nivel educativo y Uso de anticonceptivos no fueron significativas tras el ajuste por las demás variables.

### Edad (años):

Por cada año adicional de edad, las probabilidades de tener una práctica incorrecta disminuyen ligeramente en un 2% (OR = 0.98; IC 95%: 0.96–1.01; p = 0.208). Este valor no es estadísticamente significativo (p \> 0.05), sugiriendo que la edad no tiene un efecto independiente fuerte tras controlar por otras variables.

### Estado civil:

Comparado con el estado civil "Casada" (categoría de referencia): Las pacientes **Convivientes** tienen un 10% más de probabilidades de presentar una práctica incorrecta (OR = 1.10; IC 95%: 0.58–2.09; p = 0.778), pero no es significativo. Las **Solteras** tienen un 134% más de probabilidades (OR = 2.34; IC 95%: 1.09–5.33; p = 0.034), lo que indica una asociación significativa. Las **Viudas** tienen un 70% más de probabilidades (OR = 1.70; IC 95%: 0.35–12.27; p = 0.540), pero el intervalo de confianza amplio y el valor p alto reflejan una falta de significancia estadística.

### Nivel educativo:

Comparado con "Primaria" (categoría de referencia): Las pacientes con educación **Secundaria** tienen un 69% más de probabilidades de una práctica incorrecta (OR = 1.69; IC 95%: 0.21–11.20; p = 0.586), pero no es significativo. Las de nivel **Superior** tienen un 11% más de probabilidades (OR = 1.11; IC 95%: 0.14–6.89; p = 0.910), también no significativo. Los intervalos de confianza amplios indican alta variabilidad en estas estimaciones.

### Uso de anticonceptivos:

Las pacientes que **usan anticonceptivos** tienen un 71% más de probabilidades de presentar una práctica incorrecta en comparación con aquellas que no los usan (OR = 1.71; IC 95%: 0.86–3.42; p = 0.126). Aunque el valor p es mayor a 0.05, esta asociación es cercana a la significancia, sugiriendo un posible efecto que podría explorarse más.

### Número de hijos:

Por cada hijo adicional, las probabilidades de tener una práctica incorrecta disminuyen en un 23% (OR = 0.77; IC 95%: 0.60–0.99; p = 0.040). Este resultado es estadísticamente significativo, indicando que un mayor número de hijos se asocia con una menor probabilidad de práctica incorrecta.

### Grado de conocimiento:

Comparado con "Alto" (categoría de referencia): Un **grado de conocimiento Bajo** incrementa las probabilidades de tener una práctica incorrecta en un 331% (OR = 4.31; IC 95%: 1.96–10.17; p \< 0.001), lo que indica una asociación fuerte y significativa. Un **grado de conocimiento Medio** incrementa las probabilidades en un 34% (OR = 1.34; IC 95%: 0.69–2.63; p = 0.389), pero no es significativo. Un **grado de conocimiento "No conoce"** incrementa las probabilidades en un 19,227% (OR = 19.23; IC 95%: 7.95–33.00; p \< 0.001), reflejando un riesgo extremadamente elevado y significativo.
